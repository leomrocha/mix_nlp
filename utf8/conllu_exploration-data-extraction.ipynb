{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A statistical Conllu file Exploration of  Universal Dependencies\n",
    "\n",
    "## Introduction\n",
    "\n",
    "While much work is being done in the current days on NLP and NLU, there is little work on describing why a certain length of transformer (or other as LSTM time steps) architecture has been chosen for the training, it is mostly arbitrary and depends on the goal of the work and resources available (mainly hardware). These decisions are hard once the model has been trained and there is nothing that can be done to extend the length of a transformer (for example) without having to retrain the entire network. There are however some works that tackle variable length sequences. \n",
    "\n",
    "This work presents a first complete analysis of the Universal Dependencies v2.6 dataset and presents the globan and individual results of each language present in the dataset.\n",
    "\n",
    "This work does not intend to be a conference level paper (that is why there are no references to all the papers on each subject), but an informational technical report that might help to better select the most effective compromise text or token length for your particular NLP application.\n",
    "\n",
    "The number of analyzed languages is 92, the token length is measured as the named UPOS tag in the dataset, while the character length is just that. There is no analysis on what constitutes a word or not, this means that a token includes the punctuiation and other symbols presents in the text samples. For ling√ºstic analysis purposes more de\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observations\n",
    "\n",
    "The histograms show a skew on the distribution, this can be a skewed gaussian, a generalized gaussian or a beta distribution form. Due to this, I will be testing different distribution fits with the Kolmogorov-Smirnov test.\n",
    "\n",
    "There are many languages that do not have enough samples so the dsitribution fit will not be good  and errors will be big.\n",
    "This is not an issue  from the code point of view. The important thing is if this data is used, take into account the number of samples available.\n",
    "\n",
    "\n",
    "While doing this work I found quite interesting that are languages whose number of tokens or characters avoid certain bins in the histogram (Bulgarian, Breton Welsh, Danish, Slovak, Tamil and Thai are a few examples of this). This can mean that, either the language structure supports only those lengths, or that the analyzed dataset only contains samples that avoid some sentence lengths.\n",
    "\n",
    "For some languages the number of samples is too small to make any good assumption from the data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This work presents a sample length analysis by language on the UniversalDependencies v2.6 dataset presenting the statistics for all 92 represented languages. The analysis then shows the length histograms by character and token length.\n",
    "\n",
    "The best compromise for choosing a sequence length on the NLP architecture for training will depend mostly on the requirements of the applicatino, nevertheless with the numbers here you should be able to make an informed guess on what might be better for your case.\n",
    "\n",
    "We can see that having a multi-lingual approach will necessary make the needed sequences longer as there is a large variability on sequence length, but appliying to single language might allow you to optimize your neural architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Future Work\n",
    "\n",
    "I am currently working on a more in depth analysis of the complete Gutenberg project dataset ( ~60K books in several languages) that will discriminate several other text characteristics.\n",
    "\n",
    "I also have started to work on a complete parsing of a few of the Wiktionary datasets.\n",
    "\n",
    "Stay tuned for those results ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool, cpu_count\n",
    "\n",
    "import math\n",
    "import os, sys\n",
    "import orjson as json\n",
    "import pyconll\n",
    "import pyconll.util\n",
    "from pycountry import languages\n",
    "\n",
    "try:\n",
    "    from utf8.utils import *\n",
    "except:\n",
    "    # to solve issue with ipython executing this import\n",
    "    from utils import *\n",
    "\n",
    "from preprocessors.preprocess_conllu import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UD_VERSION = \"2.6\"\n",
    "# BASEPATH = \"/home/leo/projects/Datasets/text\"\n",
    "# CONLLU_BASEPATH = os.path.join(BASEPATH, 'UniversalDependencies/ud-treebanks-v{}'.format(UD_VERSION))\n",
    "CONLLU_BASEPATH = \"/home/leo/projects/Datasets/text/UniversalDependencies/ud-treebanks-v2.6\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rootdir=CONLLU_BASEPATH\n",
    "blacklist=[]  # BLACKLIST\n",
    "allconll = get_all_files_recurse(rootdir)\n",
    "train, test, dev = filter_conllu_files(allconll, blacklist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conllu_get_fields(fname):\n",
    "    \"\"\"\n",
    "    Processes one conllu file\n",
    "    :param fname: absolute path to the conllu file\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    conll = pyconll.load_from_file(fname)\n",
    "    upos = []\n",
    "    xpos = []\n",
    "    deprel = []\n",
    "    sentences = []\n",
    "    forms = []\n",
    "\n",
    "    src_lang = path_leaf(fname).split('_')[0]\n",
    "    for sen in conll:\n",
    "        sentences.append((src_lang, sen.text))\n",
    "        try:\n",
    "            forms.extend([t.form for t in sen._tokens])\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            sen_upos = [t.upos for t in sen._tokens]\n",
    "            upos.append((src_lang, sen.text, tuple(sen_upos)))\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            sen_xpos = [t.xpos for t in sen._tokens]\n",
    "            xpos.append((src_lang, sen.text, tuple(sen_xpos)))\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            sen_deprel = [t.deprel for t in sen._tokens]\n",
    "            deprel.append((src_lang, sen.text, tuple(sen_deprel)))\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    return (set(upos), len(upos)), (set(xpos), len(xpos)), (set(deprel), len(deprel)), (set(sentences), len(sentences)), (set(forms), len(forms))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _try_get_2list(fname):\n",
    "    try:\n",
    "        return conllu_get_fields(fname)\n",
    "    except Exception as e:\n",
    "        print(\"Error processing file: {} \\nWith error: {}\".format(fname, e))\n",
    "\n",
    "\n",
    "def conllu_process_get_2list(rootdir=CONLLU_BASEPATH, blacklist=BLACKLIST):\n",
    "    allconll = get_all_files_recurse(rootdir)\n",
    "    train, test, dev = filter_conllu_files(allconll, blacklist)\n",
    "    all_files = train + test + dev\n",
    "#     print(all_files)\n",
    "\n",
    "    with Pool(processes=cpu_count()) as pool:\n",
    "        res = pool.map(_try_get_2list, all_files)\n",
    "        return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.2 s, sys: 2.79 s, total: 15 s\n",
      "Wall time: 3min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "res = conllu_process_get_2list(blacklist=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding now the shortest and longest sequences, checking the length and plotting those to see what's happening with the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.04 s, sys: 154 ms, total: 2.2 s\n",
      "Wall time: 2.22 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "upos_data = []\n",
    "xpos_data = []\n",
    "deprel_data = []\n",
    "sentences_data = []\n",
    "forms_data = []\n",
    "\n",
    "for r in res:\n",
    "    upos_val, xpos_val, deprel_val, sentences_val, forms_val = r\n",
    "#     print(\"lala 1\")\n",
    "    forms_data.extend(forms_val[0])\n",
    "    for val in upos_val[0]:\n",
    "#         print(val)\n",
    "        lang1, txt1, upos  = val\n",
    "        upos_data.append((lang1, txt1, upos, len(upos)))\n",
    "    for lang2, txt2, xpos in xpos_val[0]:\n",
    "        xpos_data.append((lang2, txt2, xpos, len(xpos)))\n",
    "    for lang3, txt3, deprel in deprel_val[0]:\n",
    "        deprel_data.append((lang3, txt3, deprel, len(deprel)))\n",
    "    for lang4, txt4 in sentences_val[0]:\n",
    "        sentences_data.append((lang4, txt4, len(txt4)))\n",
    "\n",
    "# upos_data = sorted(upos_data)\n",
    "# xpos_data = sorted(xpos_data)\n",
    "# deprel_data = sorted(deprel_data)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_upos = pd.DataFrame(upos_data, columns=[\"lang\", \"text\", \"upos\", \"upos_len\"])\n",
    "df_xpos = pd.DataFrame(xpos_data, columns=[\"lang\", \"text\", \"xpos\", \"xpos_len\"])\n",
    "df_deprel = pd.DataFrame(deprel_data, columns=[\"lang\", \"text\", \"deprel\", \"deprel_len\"])\n",
    "df_txt = pd.DataFrame(sentences_data, columns=[\"lang\", \"text\", \"text_len\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['lang', 'text', 'upos', 'upos_len'], dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_upos.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     1288375\n",
       "unique         92\n",
       "top            de\n",
       "freq       204276\n",
       "Name: lang, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_upos['lang'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "langs = sorted(df_upos['lang'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(langs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modified from \n",
    "distributions = {\"norm\": stats.norm,\n",
    "                     \"skewnorm\": stats.skewnorm,\n",
    "                     \"gennorm\": stats.gennorm,\n",
    "                     \"beta\": stats.beta,\n",
    "                     }\n",
    "\n",
    "def get_best_distribution(data):\n",
    "    dist_results = []\n",
    "    params = {}\n",
    "    for dist_name, dist in distributions.items():\n",
    "        param = dist.fit(data)\n",
    "\n",
    "        params[dist_name] = param\n",
    "        # Applying the Kolmogorov-Smirnov test\n",
    "        D, p = stats.kstest(data, dist_name, args=param)\n",
    "#         print(\"p value for \"+dist_name+\" = \"+str(p))\n",
    "        dist_results.append((dist_name, D, p))\n",
    "\n",
    "    # select the best fitted distribution\n",
    "    # store the name of the best fit and its p value\n",
    "    best_dist, D, best_p = max(dist_results, key=lambda item: item[2])\n",
    "#     print(\"Best fitting distribution: \"+str(best_dist))\n",
    "#     print(\"Best p value: \"+ str(best_p))\n",
    "#     print(\"Parameters for the best fit: \"+ str(params[best_dist]))\n",
    "\n",
    "    return best_dist, best_p, params[best_dist]\n",
    "\n",
    "\n",
    "def get_stats(distribution, data):\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-35-f8f774a6cbc4>\u001b[0m in \u001b[0;36mget_best_distribution\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdist_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m# Applying the Kolmogorov-Smirnov test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkstest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdist_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;31m#         print(\"p value for \"+dist_name+\" = \"+str(p))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mdist_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv3/lib/python3.8/site-packages/scipy/stats/stats.py\u001b[0m in \u001b[0;36mkstest\u001b[0;34m(rvs, cdf, args, N, alternative, mode)\u001b[0m\n\u001b[1;32m   5501\u001b[0m         \u001b[0mvals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrvs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5502\u001b[0m         \u001b[0mN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5503\u001b[0;31m     \u001b[0mcdfvals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5504\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5505\u001b[0m     \u001b[0;31m# to not break compatibility with existing code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv3/lib/python3.8/site-packages/scipy/stats/_distn_infrastructure.py\u001b[0m in \u001b[0;36mcdf\u001b[0;34m(self, x, *args, **kwds)\u001b[0m\n\u001b[1;32m   1832\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcond\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# call only if at least 1 entry\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1833\u001b[0m             \u001b[0mgoodargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margsreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcond\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1834\u001b[0;31m             \u001b[0mplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcond\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mgoodargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1835\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1836\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv3/lib/python3.8/site-packages/scipy/stats/_distn_infrastructure.py\u001b[0m in \u001b[0;36m_cdf\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m   1707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1708\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_cdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1709\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cdfvec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1711\u001b[0m     \u001b[0;31m## generic _argcheck, _logcdf, _sf, _logsf, _ppf, _isf, _rvs are defined\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv3/lib/python3.8/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2089\u001b[0m             \u001b[0mvargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_n\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_n\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2091\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_vectorize_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2092\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2093\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_ufunc_and_otypes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv3/lib/python3.8/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36m_vectorize_call\u001b[0;34m(self, func, args)\u001b[0m\n\u001b[1;32m   2165\u001b[0m                       for a in args]\n\u001b[1;32m   2166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2167\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2169\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnout\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv3/lib/python3.8/site-packages/scipy/stats/_continuous_distns.py\u001b[0m in \u001b[0;36m_cdf_single\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m   6693\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6694\u001b[0m             \u001b[0mt1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mintegrate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6695\u001b[0;31m             \u001b[0mt2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mintegrate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6696\u001b[0m             \u001b[0mcdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mt2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6697\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcdf\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv3/lib/python3.8/site-packages/scipy/integrate/quadpack.py\u001b[0m in \u001b[0;36mquad\u001b[0;34m(func, a, b, args, full_output, epsabs, epsrel, limit, points, weight, wvar, wopts, maxp1, limlst)\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mweight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m         retval = _quad(func, a, b, args, full_output, epsabs, epsrel, limit,\n\u001b[0m\u001b[1;32m    342\u001b[0m                        points)\n\u001b[1;32m    343\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv3/lib/python3.8/site-packages/scipy/integrate/quadpack.py\u001b[0m in \u001b[0;36m_quad\u001b[0;34m(func, a, b, args, full_output, epsabs, epsrel, limit, points)\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpoints\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minfbounds\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 453\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_quadpack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_qagse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfull_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepsabs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepsrel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    454\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_quadpack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_qagie\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbound\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minfbounds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfull_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepsabs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepsrel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv3/lib/python3.8/site-packages/scipy/stats/_continuous_distns.py\u001b[0m in \u001b[0;36m_pdf\u001b[0;34m(self, x, a)\u001b[0m\n\u001b[1;32m   6685\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6686\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_pdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6687\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;36m2.\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0m_norm_pdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0m_norm_cdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6689\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_cdf_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv3/lib/python3.8/site-packages/scipy/stats/_continuous_distns.py\u001b[0m in \u001b[0;36m_norm_pdf\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_norm_pdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0m_norm_pdf_C\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "langs_data = {}\n",
    "\n",
    "\n",
    "for lang in langs:\n",
    "    try:\n",
    "#         fig, ax = plt.subplots()\n",
    "        dest_lang = languages.get(alpha_2=lang) if len(lang) == 2 else languages.get(alpha_3=lang)\n",
    "        dest_lang = dest_lang.name\n",
    "        ax.set_title(lang +\":\" +dest_lang )\n",
    "        lng_upos_len = df_upos.loc[df_upos['lang'] == lang]['upos_len']  \n",
    "        lng_deprel_len = df_deprel.loc[df_deprel['lang'] == lang]['deprel_len']\n",
    "        lng_text_len = df_txt.loc[df_txt['lang'] == lang]['text_len']\n",
    "        \n",
    "        langs_data[lang] = {\n",
    "            'lang': dest_lang,\n",
    "            'upos_len': lng_upos_len,\n",
    "            'upos_distrib': get_best_distribution(lng_upos_len),\n",
    "            'deprel_len': lng_deprel_len,\n",
    "            'deprel_distrib': get_best_distribution(lng_deprel_len),\n",
    "            'text_len': lng_text_len,\n",
    "            'text_distrib': get_best_distribution(lng_text_len),\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(\"Error processing lang {} with Exception {}\".format(lang, e))\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['af', 'aii', 'akk', 'am', 'ar', 'be', 'bg', 'bho', 'bm', 'br', 'bxr', 'ca', 'cop', 'cs', 'cu', 'cy', 'da', 'de', 'el', 'en', 'es', 'et', 'eu', 'fa', 'fi', 'fo', 'fr', 'fro', 'ga', 'gd', 'gl', 'got'])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "langs_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skewnorm\n",
      "beta\n",
      "beta\n",
      "beta\n",
      "beta\n",
      "beta\n",
      "skewnorm\n",
      "beta\n",
      "beta\n",
      "beta\n",
      "beta\n",
      "beta\n",
      "beta\n",
      "beta\n",
      "beta\n",
      "skewnorm\n",
      "beta\n",
      "beta\n",
      "beta\n",
      "beta\n",
      "skewnorm\n",
      "beta\n",
      "beta\n",
      "beta\n",
      "beta\n",
      "skewnorm\n",
      "beta\n",
      "beta\n",
      "beta\n",
      "beta\n",
      "gennorm\n",
      "beta\n"
     ]
    }
   ],
   "source": [
    "for lang in langs_data.keys():\n",
    "    print(langs_data[lang]['upos_distrib'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "fr = langs_data['fr']\n",
    "frupos = langs_data['fr']['upos_len']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lang': 'French',\n",
       " 'upos_len': 46483       3\n",
       " 46484       7\n",
       " 46485       2\n",
       " 46486       2\n",
       " 46487      11\n",
       "            ..\n",
       " 1287652    26\n",
       " 1287653    36\n",
       " 1287654    32\n",
       " 1287655    48\n",
       " 1287656    30\n",
       " Name: upos_len, Length: 44744, dtype: int64,\n",
       " 'upos_distrib': ('beta',\n",
       "  1.0539453859211309e-12,\n",
       "  (2.328372827493223,\n",
       "   888069.8279996342,\n",
       "   0.24182457861422196,\n",
       "   10057137.131721482)),\n",
       " 'deprel_len': 46505      10\n",
       " 46506      11\n",
       " 46507      11\n",
       " 46508      20\n",
       " 46509      35\n",
       "            ..\n",
       " 1287847    34\n",
       " 1287848    31\n",
       " 1287849    76\n",
       " 1287850    28\n",
       " 1287851    38\n",
       " Name: deprel_len, Length: 44752, dtype: int64,\n",
       " 'deprel_distrib': ('beta',\n",
       "  3.26424845519822e-12,\n",
       "  (2.355796340060384,\n",
       "   1549226.4004566916,\n",
       "   0.18672909753933736,\n",
       "   17352777.09409206)),\n",
       " 'text_len': 44870       98\n",
       " 44871      172\n",
       " 44872       32\n",
       " 44873       27\n",
       " 44874      364\n",
       "           ... \n",
       " 1211677     88\n",
       " 1211678     29\n",
       " 1211679     49\n",
       " 1211680     29\n",
       " 1211681    109\n",
       " Name: text_len, Length: 43830, dtype: int64,\n",
       " 'text_distrib': ('beta',\n",
       "  8.35891321224188e-43,\n",
       "  (2.1228263454385026,\n",
       "   34518805.60344483,\n",
       "   0.9606338358091495,\n",
       "   1459226735.5985203))}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leo/venv3/lib/python3.8/site-packages/scipy/stats/_continuous_distns.py:547: RuntimeWarning: invalid value encountered in sqrt\n",
      "  sk = 2*(b-a)*np.sqrt(a + b + 1) / (a + b + 2) / np.sqrt(a*b)\n",
      "/home/leo/venv3/lib/python3.8/site-packages/scipy/optimize/minpack.py:162: RuntimeWarning: The iteration is not making good progress, as measured by the \n",
      "  improvement from the last ten iterations.\n",
      "  warnings.warn(msg, RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "frupos_norm = stats.norm.fit(frupos)\n",
    "frupos_beta = stats.beta.fit(frupos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "frupos_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((26.55730377257286, 17.290024729527286),\n",
       " (2.328372827493223,\n",
       "  888069.8279996342,\n",
       "  0.24182457861422196,\n",
       "  10057137.131721482))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frupos_norm, frupos_beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p value for norm = 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leo/venv3/lib/python3.8/site-packages/scipy/stats/_continuous_distns.py:547: RuntimeWarning: invalid value encountered in sqrt\n",
      "  sk = 2*(b-a)*np.sqrt(a + b + 1) / (a + b + 2) / np.sqrt(a*b)\n",
      "/home/leo/venv3/lib/python3.8/site-packages/scipy/optimize/minpack.py:162: RuntimeWarning: The iteration is not making good progress, as measured by the \n",
      "  improvement from the last ten iterations.\n",
      "  warnings.warn(msg, RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p value for beta = 1.0539453859211309e-12\n",
      "p value for expon = 0.0\n",
      "Best fitting distribution: beta\n",
      "Best p value: 1.0539453859211309e-12\n",
      "Parameters for the best fit: (2.328372827493223, 888069.8279996342, 0.24182457861422196, 10057137.131721482)\n"
     ]
    }
   ],
   "source": [
    "best_distrib = get_best_distribution(frupos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

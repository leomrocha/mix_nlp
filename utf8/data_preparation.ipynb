{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "\n",
    "This notebook develops the data preparation for text-to-text learning for supervised datasets (like T5 from Deep Mind), it extends T5 for more tasks and is developed with PyTorch.\n",
    "\n",
    "The source code is open-sourced.\n",
    "\n",
    "For the processed text, it will be given when/if I get resources to get it in the open.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset preparation.\n",
    "\n",
    "One of the ideas of this process is to do less pre-processing and use the least pre-processed text possible. Uppercase, punctuation and other simbols have information that with some pre-processing is lost. This might not be too problematic for English or other languages, but certainly is for German (and might be for others).\n",
    "\n",
    "Due to this, many of the pre-processsd (tokenized) datasets available are discarded and the data preparation will be done from Raw data (example for the GLUE and SuperGLUE benchmmarks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Task Description\n",
    "\n",
    "In the original T5 paper the tasks are described in english and with a single representation, for example: \n",
    " \n",
    "    Source String: \"translate {}\"\n",
    "    Target String: \"to {}\"\n",
    " \n",
    "In this work we add a few variations to this. The first variation is that the task will be described in multiple languages, for starting:\n",
    "\n",
    "* English\n",
    "* Spanish\n",
    "* French\n",
    "* German\n",
    "\n",
    "The second change is that instead of a single description of the task, there will be multiple ones and they'll be chosen randomly.\n",
    "\n",
    "Examples for language translation:\n",
    " \n",
    "    \" CÃ³mo se dice: {} en {} ?\"\n",
    "    \" Traducir: {} al {}.\"\n",
    "    \" Por favor traduce: {} al {}\"\n",
    "    \" Traduce: {} al {}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets List to process/analyze\n",
    "\n",
    "* ~~MUSE~~ Issue downloading data, only multilang dictionaries available\n",
    "* GLUE\n",
    "    - [CoLA](https://nyu-mll.github.io/CoLA/); [Neural Network Acceptability Judgments ](https://arxiv.org/abs/1805.12471); [Source Code](https://github.com/nyu-mll/CoLA-baselines)\n",
    "    - MNLI\n",
    "    - MRPC\n",
    "    - QNLI\n",
    "    - QQP\n",
    "    - RTE\n",
    "    - SNLI\n",
    "    - SST-2\n",
    "    - STS-B\n",
    "    - WNLI\n",
    "* SuperGLUE\n",
    "    - BoolQ\n",
    "    - CB\n",
    "    - COPA\n",
    "    - MultiRC\n",
    "    - ReCoRD\n",
    "    - RTE\n",
    "    - WiC\n",
    "    - WSC\n",
    "* MultiNLI\n",
    "* SNLI\n",
    "* XNLI\n",
    "* UD-Treebank v2.5\n",
    "* SWAG\n",
    "* WikiMatrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsupervised Datasets\n",
    "\n",
    "* Gutenberg\n",
    "* Wiktionary\n",
    "* Wikipedia\n",
    "* ArXiv\n",
    "* Wikitext-2\n",
    "* Wikitext-103"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CoLA\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchtext.data import TabularDataset, Field\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cola_path = \"~/\"\n",
    "cola_src = Field(sequential=True,\n",
    "                tokenize=lambda x:x  # character level tokenization\n",
    "                 include_lenghts=True,  # \n",
    "                )\n",
    "cola_tgt = Field(is_target=True)\n",
    "mt_train = TabularDataset( path='/path/to/file.tsv', format=\"TSV\", fields=(_, cola_trg, _, cola_src))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "\n",
    "This notebook develops the data preparation for text-to-text learning for supervised datasets (like T5 from Deep Mind), it extends T5 for more tasks and is developed with PyTorch.\n",
    "\n",
    "The source code is open-sourced.\n",
    "\n",
    "For the processed text, it will be given when/if I get resources to get it in the open (due to data volumes).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset preparation.\n",
    "\n",
    "One of the ideas of this process is to do less pre-processing and use the least pre-processed text possible. Uppercase, punctuation and other simbols have information that with some pre-processing is lost. This might not be too problematic for English or other languages, but certainly is for German (and might be for others).\n",
    "\n",
    "Due to this, many of the pre-processsd (tokenized) datasets available are discarded and the data preparation will be done from Raw data (example for the GLUE and SuperGLUE benchmmarks)\n",
    "\n",
    "Data preparation would be much faster with Scala in Spark than with Python but for ease of portability and usage I'll be using python. Also the data preparation is one off only, no need to re-process once done.\n",
    "\n",
    "Nevertheless, even if working with Python, choosing the right libraries is good. This is why for json we choose [orjson](https://github.com/ijl/orjson) and for csv even though there seems to be a [faster library ](https://github.com/juancarlospaco/faster-than-csv) it does not have many users or community so we keep with the standard csv library which is the fastest other way of doing it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Task Description\n",
    "\n",
    "In the original T5 paper the tasks are described in english and with a single representation, for example: \n",
    " \n",
    "    Source String: \"translate {}\"\n",
    "    Target String: \"to {}\"\n",
    " \n",
    "In this work we add a few variations to this. The first variation is that the task will be described in multiple languages, for starting:\n",
    "\n",
    "* English\n",
    "* Spanish\n",
    "* French\n",
    "* German\n",
    "\n",
    "TODO The second change is that instead of a single description of the task, there will be multiple ones and they'll be chosen randomly.\n",
    "\n",
    "Examples for language translation:\n",
    " \n",
    "    \" Cómo se dice: {} en {} ?\"\n",
    "    \" Cómo se escribe: {} en {} ?\"\n",
    "    \" Escribe: {} en {} ?\"\n",
    "    \" Traducir: {} al {}.\"\n",
    "    \" Por favor traduce: {} al {}\"\n",
    "    \" Traduce: {} al {}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets List to process/analyze\n",
    "\n",
    "* ~~MUSE~~ Issue downloading data, only multilang dictionaries available\n",
    "* GLUE\n",
    "    - [CoLA](https://nyu-mll.github.io/CoLA/); [Neural Network Acceptability Judgments ](https://arxiv.org/abs/1805.12471); [Source Code](https://github.com/nyu-mll/CoLA-baselines)\n",
    "    - [MNLI](https://www.nyu.edu/projects/bowman/multinli/); [Paper](https://arxiv.org/abs/1704.05426); [Baseline](https://github.com/nyu-mll/multiNLI/blob/master/README.md)\n",
    "    - MRPC [Paper](https://pdfs.semanticscholar.org/13d7/cbe9035abbb0f243a5e63e19d9c01bcf69d8.pdf); [Original Dataset](https://www.microsoft.com/en-us/download/details.aspx?id=52398&from=http%3A%2F%2Fresearch.microsoft.com%2Fen-us%2Fdownloads%2F607d14d9-20cd-47e3-85bc-a2f65cd28042%2F)\n",
    "    - QNLI [Paper](https://www.nyu.edu/projects/bowman/glue.pdf) \n",
    "    - QQP\n",
    "    - RTE\n",
    "    - SNLI\n",
    "    - SST-2\n",
    "    - STS-B\n",
    "    - WNLI\n",
    "* [SuperGLUE](https://w4ngatang.github.io/static/papers/superglue.pdf) \n",
    "    - BoolQ\n",
    "    - CB\n",
    "    - COPA\n",
    "    - MultiRC\n",
    "    - ReCoRD\n",
    "    - RTE\n",
    "    - WiC\n",
    "    - WSC\n",
    "* [XNLI](https://github.com/facebookresearch/XNLI) <- this one is interesting\n",
    "* UD-Treebank v2.5 <- this one is interesting\n",
    "* [SWAG](http://rowanzellers.com/swag/); [Paper](https://arxiv.org/abs/1808.05326); [Source Code](https://github.com/rowanz/swagaf)\n",
    "* [WikiMatrix](https://ai.facebook.com/blog/wikimatrix/); [Paper](https://arxiv.org/abs/1907.05791); [Github](https://github.com/facebookresearch/LASER/tree/master/tasks/WikiMatrix)\n",
    "* ~~[SETimes](http://nlp.ffzg.hr/resources/corpora/setimes/)~~ No need of it, already many samples at WikiMatrix and UD-Treebank\n",
    "* Tatoeba:  Wikimatrix is nice but this one has different kind of phrases (questions, answers and some other things)\n",
    "* [EuroParliament](http://www.statmt.org/europarl/)\n",
    "* [Wikipedia Translation Dataset](http://opus.nlpl.eu/Wikipedia.php); [WikiExtractor](https://github.com/tatuylonen/wiktextract)\n",
    "* [ConceptNET](http://conceptnet.io/); [Github](https://github.com/commonsense/conceptnet5/wiki) \n",
    "* [Open Multilingual WordNet](http://compling.hss.ntu.edu.sg/omw/) and [Global WordNet Association](http://globalwordnet.org/resources/wordnets-in-the-world/)\n",
    "\n",
    "\n",
    "* [BabelNET](https://babelnet.org/) [Downloads](https://babelnet.org/download) seem proprietary ...\n",
    "* [PanLex](https://panlex.org/)  Word level traductions for many (many) language pairs. [Downloads](https://panlex.org/source-list/) and [Vocabulary](https://vocab.panlex.org/)\n",
    "* [ASJD Database](https://asjp.clld.org)\n",
    "* Thesaurus [Some](https://old.datahub.io/dataset/open-data-thesaurus) [links](http://vocabulary.semantic-web.at/PoolParty/wiki/OpenData) [where](https://www.thesaurus.net/) [to](https://www.powerthesaurus.org/multilingual) find\n",
    "\n",
    "* [bAbI](https://research.fb.com/downloads/babi/); [Code on Github](https://github.com/facebook/bAbI-tasks). Although it seems that there are [issues](https://www.reddit.com/r/MachineLearning/comments/3ohkt8/i_solved_facebooks_babi_and_found_lots_of_errors/) in the [dataset](http://jamesknighton.com/2015/babi/)\n",
    "* [MALMO](https://www.microsoft.com/en-us/research/project/project-malmo/) Minecraft Artificial Intelligence; [Github](https://github.com/Microsoft/malmo)\n",
    "\n",
    "### Question Answering:\n",
    "\n",
    "* XuAD;  [Paper](https://arxiv.org/abs/1910.11856) [Dataset](https://github.com/deepmind/xquad)\n",
    "* XQA; [Paper](https://www.aclweb.org/anthology/P19-1227/)\n",
    "* MLQA; [Paper](https://arxiv.org/abs/1910.07475)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsupervised Datasets\n",
    "\n",
    "* Gutenberg\n",
    "* [Wiktionary](https://dumps.wikimedia.org/enwiktionary/)\n",
    "* Scholarpedia\n",
    "* [Wikipedia](https://dumps.wikimedia.org/)\n",
    "* ArXiv\n",
    "* Wikitext-2\n",
    "* Wikitext-103 \n",
    "\n",
    "## Source Code (Programming) Datasets\n",
    "\n",
    "* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CoLA\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNLI - MultiNLI Dataset\n",
    "\n",
    "There are more than one task that are possible as the dataset contains also the parse tree for each sentence, which is nice. So the output format of the json will be:\n",
    "\n",
    "    {\n",
    "        'input': \"task: MNLI | Sentence 1: {} | Sentence 2: {}\".format(sentence_1, sentence_2),\n",
    "        'target': e['gold_label'],\n",
    "        'input_sentence_1': \"task: MNLI parse tree of: {}\".format(sentence_1),\n",
    "        'input_sentence_2': \"task: MNLI parse tree of: {}\".format(sentence_2),\n",
    "        'parse_target_1': e['sentence1_parse'],\n",
    "        'parse_target_2': e['sentence2_parse'],\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MRPC \n",
    "\n",
    "\n",
    "\n",
    "This data consists of 5 columns:\n",
    "\n",
    "    label: 0 Not equivalent, 1 semantically equivalent\n",
    "    sentence 1 id\n",
    "    sentence 2 id\n",
    "    sentence 1 text\n",
    "    sentence 2 text\n",
    "    \n",
    "    \n",
    "    \n",
    "The note to make is that the dataset is already tokenized meaning is not the raw text. Nothing else will be done to the text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QNLI\n",
    "\n",
    "The dataset download contains the following columns:\n",
    "\n",
    "    ndex\n",
    "    Question\n",
    "    Sentence\n",
    "    Label - [entailment|not_entailment]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QQP\n",
    "\n",
    "Columns in the dataset:\n",
    "\n",
    "    id\n",
    "    qid1\n",
    "    qid2\n",
    "    question1\n",
    "    question2\n",
    "    is_duplicate\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocess import process_glue, process_superglue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opening /home/leo/projects/Datasets/text/GLUE/MNLI/original/multinli_1.0_dev_mismatched.jsonl\n",
      "opening /home/leo/projects/Datasets/text/GLUE/CoLA/dev.tsv\n",
      "opening /home/leo/projects/Datasets/text/GLUE/CoLA/test.tsv\n",
      "opening /home/leo/projects/Datasets/text/GLUE/CoLA/train.tsv\n",
      "opening /home/leo/projects/Datasets/text/GLUE/MRPC/dev_ids.tsv\n",
      "opening /home/leo/projects/Datasets/text/GLUE/MNLI/original/multinli_1.0_dev_matched.jsonl\n",
      "saving to /home/leo/projects/Datasets/text/GLUE/CoLA/dev-txt2txt.json\n",
      "saving to /home/leo/projects/Datasets/text/GLUE/MRPC/dev_ids-txt2txt.json\n",
      "saving to /home/leo/projects/Datasets/text/GLUE/CoLA/test-txt2txt.json\n",
      "opening /home/leo/projects/Datasets/text/GLUE/MRPC/test.tsv\n",
      "opening /home/leo/projects/Datasets/text/GLUE/MNLI/original/multinli_1.0_train.jsonl\n",
      "opening /home/leo/projects/Datasets/text/GLUE/MRPC/dev.tsv\n",
      "opening /home/leo/projects/Datasets/text/GLUE/MRPC/train.tsv\n",
      "saving to /home/leo/projects/Datasets/text/GLUE/MRPC/test-txt2txt.json\n",
      "opening /home/leo/projects/Datasets/text/GLUE/QNLI/test.tsv\n",
      "saving to /home/leo/projects/Datasets/text/GLUE/MRPC/dev-txt2txt.json\n",
      "opening /home/leo/projects/Datasets/text/GLUE/QNLI/dev.tsv\n",
      "opening /home/leo/projects/Datasets/text/GLUE/QNLI/train.tsv\n",
      "saving to /home/leo/projects/Datasets/text/GLUE/MRPC/train-txt2txt.json\n",
      "saving to /home/leo/projects/Datasets/text/GLUE/CoLA/train-txt2txt.json\n",
      "saving to /home/leo/projects/Datasets/text/GLUE/QNLI/test-txt2txt.json\n",
      "opening /home/leo/projects/Datasets/text/GLUE/QQP/train.tsv\n",
      "opening /home/leo/projects/Datasets/text/GLUE/QQP/dev.tsv\n",
      "saving to /home/leo/projects/Datasets/text/GLUE/QNLI/dev-txt2txt.json\n",
      "opening /home/leo/projects/Datasets/text/GLUE/QQP/test.tsv\n",
      "opening /home/leo/projects/Datasets/text/GLUE/RTE/train.tsv\n",
      "saving to /home/leo/projects/Datasets/text/GLUE/RTE/train-txt2txt.json\n",
      "opening /home/leo/projects/Datasets/text/GLUE/RTE/test.tsv\n",
      "saving to /home/leo/projects/Datasets/text/GLUE/RTE/test-txt2txt.json\n",
      "opening /home/leo/projects/Datasets/text/GLUE/RTE/dev.tsv\n",
      "saving to /home/leo/projects/Datasets/text/GLUE/MNLI/original/multinli_1.0_dev_matched-txt2txt.json\n",
      "saving to /home/leo/projects/Datasets/text/GLUE/MNLI/original/multinli_1.0_dev_mismatched-txt2txt.json\n",
      "saving to /home/leo/projects/Datasets/text/GLUE/RTE/dev-txt2txt.json\n",
      "opening /home/leo/projects/Datasets/text/GLUE/SNLI/original/snli_1.0_dev.jsonl\n",
      "opening /home/leo/projects/Datasets/text/GLUE/SNLI/original/snli_1.0_train.jsonl\n",
      "opening /home/leo/projects/Datasets/text/GLUE/SNLI/original/snli_1.0_test.jsonl\n",
      "saving to /home/leo/projects/Datasets/text/GLUE/QQP/dev-txt2txt.json\n",
      "saving to /home/leo/projects/Datasets/text/GLUE/SNLI/original/snli_1.0_test-txt2txt.json\n",
      "saving to /home/leo/projects/Datasets/text/GLUE/SNLI/original/snli_1.0_dev-txt2txt.json\n",
      "opening /home/leo/projects/Datasets/text/GLUE/SST-2/train.tsv\n",
      "opening /home/leo/projects/Datasets/text/GLUE/SST-2/test.tsv\n",
      "saving to /home/leo/projects/Datasets/text/GLUE/SST-2/test-txt2txt.json\n",
      "opening /home/leo/projects/Datasets/text/GLUE/SST-2/dev.tsv\n",
      "opening /home/leo/projects/Datasets/text/GLUE/STS-B/train.tsv\n",
      "saving to /home/leo/projects/Datasets/text/GLUE/SST-2/dev-txt2txt.json\n",
      "opening /home/leo/projects/Datasets/text/GLUE/STS-B/test.tsv\n",
      "saving to /home/leo/projects/Datasets/text/GLUE/STS-B/train-txt2txt.json\n",
      "saving to /home/leo/projects/Datasets/text/GLUE/STS-B/test-txt2txt.json\n",
      "opening /home/leo/projects/Datasets/text/GLUE/STS-B/dev.tsv\n",
      "opening /home/leo/projects/Datasets/text/GLUE/WNLI/train.tsv\n",
      "saving to /home/leo/projects/Datasets/text/GLUE/STS-B/dev-txt2txt.json\n",
      "saving to /home/leo/projects/Datasets/text/GLUE/WNLI/train-txt2txt.json\n",
      "opening /home/leo/projects/Datasets/text/GLUE/WNLI/test.tsv\n",
      "opening /home/leo/projects/Datasets/text/GLUE/WNLI/dev.tsv\n",
      "saving to /home/leo/projects/Datasets/text/GLUE/WNLI/dev-txt2txt.json\n",
      "saving to /home/leo/projects/Datasets/text/GLUE/WNLI/test-txt2txt.json\n",
      "saving to /home/leo/projects/Datasets/text/GLUE/SST-2/train-txt2txt.json\n",
      "saving to /home/leo/projects/Datasets/text/GLUE/QNLI/train-txt2txt.json\n",
      "saving to /home/leo/projects/Datasets/text/GLUE/QQP/test-txt2txt.json\n",
      "saving to /home/leo/projects/Datasets/text/GLUE/QQP/train-txt2txt.json\n",
      "saving to /home/leo/projects/Datasets/text/GLUE/MNLI/original/multinli_1.0_train-txt2txt.json\n",
      "saving to /home/leo/projects/Datasets/text/GLUE/SNLI/original/snli_1.0_train-txt2txt.json\n",
      "CPU times: user 42.1 ms, sys: 25.5 ms, total: 67.6 ms\n",
      "Wall time: 3.65 s\n"
     ]
    }
   ],
   "source": [
    "%time process_glue()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SuperGLUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opening /home/leo/projects/Datasets/text/SuperGLUE/BoolQ/test.jsonl\n",
      "opening /home/leo/projects/Datasets/text/SuperGLUE/CB/val.jsonl\n",
      "opening /home/leo/projects/Datasets/text/SuperGLUE/BoolQ/val.jsonl\n",
      "opening /home/leo/projects/Datasets/text/SuperGLUE/CB/test.jsonl\n",
      "opening /home/leo/projects/Datasets/text/SuperGLUE/BoolQ/train.jsonl\n",
      "opening /home/leo/projects/Datasets/text/SuperGLUE/ReCoRD/val.jsonl\n",
      "saving to /home/leo/projects/Datasets/text/SuperGLUE/CB/val-txt2txt.json\n",
      "saving to /home/leo/projects/Datasets/text/SuperGLUE/CB/test-txt2txt.json\n",
      "opening /home/leo/projects/Datasets/text/SuperGLUE/RTE/val.jsonl\n",
      "opening /home/leo/projects/Datasets/text/SuperGLUE/ReCoRD/train.jsonl\n",
      "opening /home/leo/projects/Datasets/text/SuperGLUE/CB/train.jsonl\n",
      "opening /home/leo/projects/Datasets/text/SuperGLUE/ReCoRD/test.jsonl\n",
      "saving to /home/leo/projects/Datasets/text/SuperGLUE/CB/train-txt2txt.json\n",
      "opening /home/leo/projects/Datasets/text/SuperGLUE/RTE/test.jsonl\n",
      "saving to /home/leo/projects/Datasets/text/SuperGLUE/RTE/val-txt2txt.json\n",
      "saving to /home/leo/projects/Datasets/text/SuperGLUE/RTE/test-txt2txt.json\n",
      "saving to /home/leo/projects/Datasets/text/SuperGLUE/BoolQ/test-txt2txt.json\n",
      "opening /home/leo/projects/Datasets/text/SuperGLUE/WiC/val.jsonl\n",
      "opening /home/leo/projects/Datasets/text/SuperGLUE/WiC/test.jsonl\n",
      "saving to /home/leo/projects/Datasets/text/SuperGLUE/BoolQ/val-txt2txt.json\n",
      "opening /home/leo/projects/Datasets/text/SuperGLUE/RTE/train.jsonl\n",
      "saving to /home/leo/projects/Datasets/text/SuperGLUE/WiC/test-txt2txt.json\n",
      "saving to /home/leo/projects/Datasets/text/SuperGLUE/WiC/val-txt2txt.json\n",
      "opening /home/leo/projects/Datasets/text/SuperGLUE/WiC/train.jsonl\n",
      "opening /home/leo/projects/Datasets/text/SuperGLUE/WSC/val.jsonl\n",
      "opening /home/leo/projects/Datasets/text/SuperGLUE/WSC/test.jsonl\n",
      "saving to /home/leo/projects/Datasets/text/SuperGLUE/BoolQ/train-txt2txt.json\n",
      "saving to /home/leo/projects/Datasets/text/SuperGLUE/WSC/test-txt2txt.json\n",
      "opening /home/leo/projects/Datasets/text/SuperGLUE/WSC/train.jsonl\n",
      "saving to /home/leo/projects/Datasets/text/SuperGLUE/WSC/train-txt2txt.json\n",
      "saving to /home/leo/projects/Datasets/text/SuperGLUE/RTE/train-txt2txt.json\n",
      "saving to /home/leo/projects/Datasets/text/SuperGLUE/WSC/val-txt2txt.json\n",
      "saving to /home/leo/projects/Datasets/text/SuperGLUE/WiC/train-txt2txt.json\n",
      "saving to /home/leo/projects/Datasets/text/SuperGLUE/ReCoRD/val-txt2txt.json\n",
      "saving to /home/leo/projects/Datasets/text/SuperGLUE/ReCoRD/test-txt2txt.json\n",
      "saving to /home/leo/projects/Datasets/text/SuperGLUE/ReCoRD/train-txt2txt.json\n",
      "CPU times: user 23.4 ms, sys: 14.4 ms, total: 37.8 ms\n",
      "Wall time: 843 ms\n"
     ]
    }
   ],
   "source": [
    "%time process_superglue()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SwagAF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Universal Dependencies v2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from preprocess_conllu import conllu_process\n",
    "from preprocess_conllu import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 40.3 ms, sys: 46.1 ms, total: 86.3 ms\n",
      "Wall time: 1min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "conllu_process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_wm = get_all_files_recurse(\"/media/nfs/Datasets/text/WikiMatrix/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WikiMatrix\n",
    "\n",
    "File structure is:\n",
    " \n",
    "    v1/*.gz - 65 GB\n",
    "    vi/SMALL/*.gz - 4,6GB\n",
    "    \n",
    "We can use all the big files for the training and the small ones for validation. Checking the files they are different language pairs, so this can be used for Zero-Shot learning on translation pairs.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocess_wikimatrix import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "wikimedia_process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3545"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([1620, 1925])  # 1620 are the complete files, 1925 are the files in the SMALL dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "WIKIMATRIX_BASEPATH = \"/media/nfs/Datasets/text/WikiMatrix/v1\"\n",
    "\n",
    "allfiles = get_all_files_recurse(WIKIMATRIX_BASEPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2t = [f for f in allfiles if 'txt2txt' in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3545"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(t2t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3545 files processed and 3545 files existing, everything seems OK."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation by length and task\n",
    "\n",
    "This part checks some things that should work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import os\n",
    "import ntpath\n",
    "import orjson as json\n",
    "\n",
    "try:\n",
    "    from .utils import *\n",
    "except:\n",
    "    # hack to solve issue with ipython executing this import\n",
    "    from utils import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfile = '/home/leo/projects/Datasets/text/SuperGLUE/CB/val-txt2txt.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = json.loads(open(tfile, 'rb').read())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "MAX_LENS = (0, 64, 128, 256, 384, 512, 768, 1024, 2048)\n",
    "def _group_foo(x, arr=np.array(MAX_LENS)):\n",
    "    ml = max(len(x[\"input\"]), len(x[\"target\"]))\n",
    "    am = np.argmax( arr > ml)\n",
    "    return arr[am]\n",
    "\n",
    "groups = {}\n",
    "uniquekeys = set([])\n",
    "for k,g in itertools.groupby(f, _group_foo):\n",
    "    if k in groups:\n",
    "        groups[k].extend(list(g))\n",
    "    else:\n",
    "        groups[k] = list(g)\n",
    "    uniquekeys.add(k)\n",
    "    \n",
    "groups = OrderedDict(sorted(groups.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{128, 256, 384, 512, 768, 1024, 2048}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "uniquekeys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128 1\n",
      "256 12\n",
      "384 19\n",
      "512 14\n",
      "768 6\n",
      "1024 2\n",
      "2048 2\n"
     ]
    }
   ],
   "source": [
    "for k,v in groups.items():\n",
    "    print(k, len(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'input': \"What is the relationship between: A: so I don't know if I wasn't drug tested based on that or because the man who hired me didn't request the drug test, because I know that my company does drug testing on occasion. B: Right. Well, for instance, does the company you worked for before have the right or do they have the ability to say, hey, we've already drug tested her and she came up negative. A: Well, no, I don't think they can force another company to not drug test me just by saying that I didn't, I mean, and they can force another company to not drug test her\",\n",
       "  'target': 'Contradiction'},\n",
       " {'input': \"What is the relationship between: Whether the relationship had gone beyond friendship Dalgliesh would now never know. She had, apparently, spent little of the money on herself, had been a dependable benefactress of the few eccentric charities of which she approved, had remembered them in her will, but without egregious generosity, and had left the residue of her estate to him without explanation, admonition or peculiar protestations of affection, although he had no doubt that the words ``my dearly beloved nephew'' meant exactly what they said. He had liked her respected her had always been at ease in her company but he had never thought that he really knew her and now he never would. and Dalgliesh really knew his aunt\",\n",
       "  'target': 'Contradiction'},\n",
       " {'input': \"What is the relationship between: A: And I haven't quite figured that out, if they figure they have got it won or if there's no real hurry because the first three quarters or, uh, uh, if something happens that that adrenalin starts flowing. They say, hey, we got to do something now. And then start playing the game the way the game should be played toward the last few minutes. B: Yeah. A: So, I don't know I'm looking for a good year. I guess we're always looking for a good year. B: So, obviously though, do you think they're going to do anything in the playoffs to make it to the Super Bowl this year and they're going to do anything in the playoffs to make it to the Super Bowl this year\",\n",
       "  'target': 'Neutral'},\n",
       " {'input': \"What is the relationship between: Who knows how many quarrels, false accusations, unnecessary dismissals, how many promising careers cut short can be attributed to a butler's slovenliness at the stage of drawing up the staff plan? Indeed, I can say I am in agreement with those who say that the ability to draw up a good staff plan is the cornerstone of any decent butler's skills. I have myself devised many staff plans over the years and I do not believe I am being unduly boastful if I say that very few ever needed amendment. and very few plans ever needed amendment\",\n",
       "  'target': 'Entailment'},\n",
       " {'input': \"What is the relationship between: Mr. Steinberg made a $59.7 million profit on the sale to Disney of his investment in the company in 1984. But lawyers said Mr. Steinberg probably faced much more potential liability because, when he sued Disney during his takeover battle, he filed on behalf of all shareholders. When Disney offered to pay Mr. Steinberg a premium for his shares, the New York investor didn't demand the company also pay a premium to other shareholders. and the company would also pay a premium to other shareholders\",\n",
       "  'target': 'Contradiction'},\n",
       " {'input': \"What is the relationship between: A: Now the part about where you said the apartment complex puts up signs that says no soliciting, I've even gone so far as to put that, I've got a storm door on the front of the house and I've put, in, I don't know how much clearer it can be, it's a red sign with silver letters saying no soliciting. I guess I should make another one that says religious or otherwise, cause I still get, B: Yeah, yeah, that's true, yeah. No I didn't go that far but, uh, yeah I probably could do the same thing, uh, you know, I don't have a storm door, but I'm sure I could rig up something. But you know I don't think that that would stop people. and a no soliciting sign would stop people\",\n",
       "  'target': 'Contradiction'}]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groups[768]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

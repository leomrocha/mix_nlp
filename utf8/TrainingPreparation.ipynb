{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Preparation\n",
    "\n",
    "This document states the goals for the training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goals\n",
    "For the current work the training is focused in learning language representations for:\n",
    "* multi-lingual\n",
    "* multi-task\n",
    "* Text-to-Text (similar to T5 from DeepMind) \n",
    "\n",
    "With the goal of:\n",
    "\n",
    "* [Few-Shot|Zero-Shot] learning of new tasks\n",
    "* Zero-Shot translation for language pairs\n",
    "* Being able to add new knowledge without catastrophic forgetting\n",
    "\n",
    "The particularity of the trained model is that they are intended to be able to recognize and solve the given tasks solely from the description in the input. The models should be able to perform well enough without any retraining or fine-tunning. Any re-training or fine-tunning should also be able to be done without hindering (much?) the previously trained tasks.\n",
    "\n",
    "Also there is the important point to make that all this work focuses on having an input as RAW as possible (meaning no text normalization, separation, .... etc) and having NO Out of Vocabulary (OOV) input. So all the languages should be feasible as input.\n",
    "\n",
    "\n",
    "## Model Outputs\n",
    "\n",
    "Particularly the model should have multiple outputs being those the following:\n",
    "\n",
    "1. Origin Language (language detection) - Language Name (would be less confusing and more informative than code)\n",
    "~~2. Destination Language (the original one if none given) - Language Name~~\n",
    "~~3. Task Language (The language in which the task was described) - Language CODE (2 or 3 character code)~~\n",
    "4. The task at hand\n",
    "5. **The TARGET output** of the task for the current input\n",
    "\n",
    "~~5. PoS UPOS tagging ckech if needed or useful?~~\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "The current work follows the example of [ERNIE 2.0](https://arxiv.org/abs/1907.12412) in that uses supervised training to improve the performance. In that paper they show that supervised tasks allow better training than just Denoising LM target with unsupervised learning. \n",
    "In this work we leverage many other tasks and meta-learning to take advantage of existing mono and multi-lingual training datasets.\n",
    "\n",
    "The training will be done in the following stages:\n",
    "\n",
    "1. A general pre-training with many datapoints on all the tasks\n",
    "    - Evaluation on different validation sets\n",
    "2. A few-shot meta-learninig training based on the pre-trained weights\n",
    "    - Evaluation on different validation sets\n",
    "3. Add architectural changes to the network (parallel columns and memory) and train for tasks with the meta-learned \n",
    "    - Evaluation on different validation sets and tasks\n",
    "4. Overfit new input or input that fails -> create an entry in the memory for it.\n",
    "    - Evaluate\n",
    "5. ... ?\n",
    "\n",
    "\n",
    "The intuition between all this is:\n",
    " - Having a strong statistical baseline with many tasks\n",
    " - Meta-learning to be able to quickly learn new tasks\n",
    " - Use the few-shot learn ability to be able to add new knowledge in the memory as in [Large Memory Layers with Product Keys](https://arxiv.org/abs/1907.052420)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Tasks\n",
    "\n",
    "The tasks to prepare for the training, many of these are intended solely for training and there is no interest in a validation dataset for these for comparison with other models as they are not available in the literature. The current work does not intend to add new tasks or metrics.\n",
    "\n",
    "The default task is to denoise and correct the input (if for example there are multiple spaces together, or diacritics missing, uppercases, etc).\n",
    "\n",
    "Many of the tasks can be taken from standard Text pre-processing tasks, the idea being here to use available weakly-supervised with minimal transformations in the input.\n",
    "\n",
    "The tasks can be separated into:\n",
    "\n",
    "### [Un|Weakly]-supervised\n",
    "\n",
    "* MLM (Masked Language Model) BERT|mBERT|BART|ERNIE training objective (TODO) \n",
    "* Denoising (see previous pont instead)\n",
    "* Capitalization\n",
    "* to-Lowercase\n",
    "* to-UPPERCASE\n",
    "* Add diacritics\n",
    "* Remove Diacritics\n",
    "* character shuffling, character deletion, character addition (close in vocab to the ones in the sentence), character duplication, ...\n",
    "~~* Text Normalization: [NFD|NFKC|...]~~ This is done before passing the text to the NN.\n",
    "\n",
    "\n",
    "### Supervised\n",
    "\n",
    "* [GLUE](https://gluebenchmark.com/)\n",
    "* [SuperGLUE](https://super.gluebenchmark.com/); [Paper](https://w4ngatang.github.io/static/papers/superglue.pdf) \n",
    "* Grammar tagging and recognition (PoS, NER, Dependency detection, ...) [UD-Treebank v2.5](https://universaldependencies.org/)\n",
    "* Translation [WikiMatrix](https://ai.facebook.com/blog/wikimatrix/); [Paper](https://arxiv.org/abs/1907.05791); [Github](https://github.com/facebookresearch/LASER/tree/master/tasks/WikiMatrix)\n",
    "* Language Detection (the goal would be to have this as an extra output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TODO but easy to make during data preparation:\n",
    "\n",
    "* Add accents to string in ASCII ,remove accents (for French, Spanish and other languages like these) .... [Answer in stackoverflow](https://stackoverflow.com/questions/517923/what-is-the-best-way-to-remove-accents-in-a-python-unicode-string) and [open science](https://www.science-emergence.com/Articles/How-to-remove-string-accents-using-python-3/) with [Gensim](https://radimrehurek.com/gensim/utils.html#gensim.utils.deaccent), should also do Remove Diacritics ...\n",
    "* Fill the placeholder (for example eliminate only one word and make it fill it ...?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TODO - prepare and do the following too:\n",
    "\n",
    "* Tatoeba:  Wikimatrix is nice but this one has different kind of phrases (questions, answers and some other things)\n",
    "* [EuroParliament](http://www.statmt.org/europarl/)\n",
    "* [Wikipedia Translation Dataset](http://opus.nlpl.eu/Wikipedia.php); [WikiExtractor](https://github.com/tatuylonen/wiktextract)\n",
    "* [ConceptNET](http://conceptnet.io/); [Github](https://github.com/commonsense/conceptnet5/wiki) \n",
    "* [Open Multilingual WordNet](http://compling.hss.ntu.edu.sg/omw/) and [Global WordNet Association](http://globalwordnet.org/resources/wordnets-in-the-world/)\n",
    "\n",
    "\n",
    "* Conjugate verbs for different languages -> do as with the language textbooks !!!\n",
    "* Give the dictionary definition of word ...\n",
    "\n",
    "\n",
    "While the starting datasets and tasks are given here, there are many others like multi-hop search and question answering that I would love to add later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Corruption techniques\n",
    "\n",
    "### BART pre-training details - Noise Generation Techniques:\n",
    "\n",
    "* Token Masking\n",
    "* Token Deletion\n",
    "* Tex Infilling\n",
    "~~* Sentence Permutation~~ Can't use in the current setting, need more dev for this\n",
    "~~* Document Rotation~~ Can't use in the current setting, need more dev for this\n",
    "\n",
    "### Other Techniques\n",
    "* Explained \n",
    "\n",
    "### Add a noise layer every N layers in the NN\n",
    "\n",
    "TODO, this is a technique that should be tested too, this might be enough for another paper\n",
    "\n",
    "There is one on that subject: [Adaptive Noise Injection: A Structure-Expanding Regularization for RNN](https://arxiv.org/abs/1907.10885)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks to test\n",
    "\n",
    "The Neural Networks to test will be the following:\n",
    "\n",
    "* Vanilla CNN (autoencoder like, non seq2seq but the input length can change if fully convolutional), this is for easy baseline\n",
    "* ~~Vanilla LSTM ?? -> might be slow/heavy to train~~\n",
    "* Vanilla Transformer Encoder only (non seq2seq)\n",
    "* Vanilla Transformer Decoder only (non seq2seq??)\n",
    "* Transformer (Encoder-Decoder Seq2Seq architecture - limit the number of parameters here, to study)\n",
    "* [Reformer: The Efficient Transformer](https://arxiv.org/abs/2001.04451)\n",
    "* Hybrid Seq2Seq (description below - goal to cut as many params as possible and ):\n",
    "    - CNN + Light Dynamic Convolutions at input level  (if possible compress the time dimension)\n",
    "    - Encoder [Transformer|Reformer] layers With Large Memory \n",
    "    - Decoder [Transformer|Reformer] Layers with Large Memory\n",
    "    - Deconv CNN +  Light Dynamic Convolution (to decompress the input time dimension into tokens)\n",
    "\n",
    "\n",
    "### Modifications to network and training\n",
    "\n",
    "All networks should also test the following modifications (though I incline myself to just do it in the hybrid architecture due to expense) \n",
    "\n",
    "* Use REPTILE (better for rsource usage than MAML) for meta-training\n",
    "* Use Plastic (hebbian?) + Modulated Plastic meta-learning\n",
    "* Use NeuralDB\n",
    "* Use Overfitting for new tasks and for examples where there are errors, overfit in a new memory position and later do attention over the memory outputs\n",
    "* The encoder just as a circular convolution of the inputs instead of making some comples NN ?? \n",
    "* Use [The Evolved Transformer](https://arxiv.org/abs/1901.11117) instead of the base Transformer (need to be implemented in pytorch)\n",
    "* Use Relative Positional Encoding and keeping past activations from TransformerXL\n",
    "* Use Compressive Transformers' ideas\n",
    "\n",
    "\n",
    "After finding a couple of AMAZING papers from google The goal should be to work on:\n",
    "* [Universal Transformers](https://arxiv.org/abs/1807.03819)\n",
    "* [MEMO: A Deep Network for Flexible Combination of Episodic Memories](https://arxiv.org/abs/2001.10913)\n",
    "\n",
    "And try to make from these two (adding circular convolution compression and/or/ reptile and plasticity) the NeuralDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Tasks and Metrics\n",
    "\n",
    "The tasks that will be given importance at the validation moment and should be used for comparison with other SoTA models available in the literature.\n",
    "\n",
    "* GLUE: standard by the site's validation set\n",
    "* SuperGLUE: standard by the site's validation set\n",
    "* Translation [BLEU](https://en.wikipedia.org/wiki/BLEU), [F-Score](https://en.wikipedia.org/wiki/F1_score), [ROUGE](https://en.wikipedia.org/wiki/F1_score) ... ?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture Description and decisions\n",
    "\n",
    "\n",
    "* As with [BART](https://arxiv.org/pdf/1910.13461.pdf) use a *Bidirectional Encoder* with an *Autoregressive Decoder* \n",
    "\n",
    "* The model will be a Seq2Seq based on the transformer architecture, the input and output sizes should be of dynamic dimension. The input dimension, if possible will be compressed by the network (example, from an original input of 1024 go to a dimension of 384 or 256).\n",
    "* The dimensions will be divisible by 2, and mostly power of 2\n",
    "\n",
    "* The model will have as an input a character level of 128 dimensions based on 3-segment UTF-8 text encoder developed previously by the same author. No OOV characters should exist for most languages and input types (only emojis and extended lost languages as egyptian will not be represented, all that is represented by the 4th segment on the UTF-8 encoding, the last code-point used will be U+FFFF). This is to be able to encode most (if not all) the languages in the available datasets for the current work. Using a 2-segment based coding for utf-8 would be much more memory and processor savy but would leave JCK languages OOV which we don't want.\n",
    "\n",
    "* The decoding from vector to text will be done at character-level based on the [FAISS facebook's library](https://github.com/facebookresearch/faiss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Tools\n",
    "\n",
    "* Development in PyTorch (easiest for research and the one the authors know best)\n",
    "* Tensorboard with torch-tensorboard to check during training\n",
    "* Mixed Precision training with [NVIDIA Apex](https://github.com/NVIDIA/apex)\n",
    "\n",
    "## Training Techniques:\n",
    "\n",
    "Most of the issues in training will be due to memory, so for this there are the following techniques to use:\n",
    "\n",
    "* [Gradient Checkpointing](https://arxiv.org/abs/1604.06174); [Fitting larger networks into memory.\n",
    "](https://medium.com/tensorflow/fitting-larger-networks-into-memory-583e3c758ff9) in [Pytorch](https://qywu.github.io/2019/05/22/explore-gradient-checkpointing.html)\n",
    "* [Reformer - Google](https://arxiv.org/pdf/2001.04451.pdf)\n",
    "* [Reversible Residual Network: Backpropagation Without Storing Activations](https://arxiv.org/abs/1707.04585) [some](https://github.com/tbung/pytorch-revnet) [sources](https://github.com/renmengye/revnet-public)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limitations and Specifications\n",
    "\n",
    "The entire development, pre-processing and training is to be limited to the following software and HW:\n",
    "\n",
    "    System Ubuntu 19.04\n",
    "    Python 3.7\n",
    "    PyTorch+=1.4\n",
    "\n",
    "\n",
    "    CPU = 8 core intel i7700\n",
    "    GPU_1 = RTX 2080 Ti - 11GB RAM\n",
    "    GPU_2 = GTX 1080 - 8 GB RAM ( -1GB for the system that uses it)\n",
    "    RAM = 64 GB\n",
    "    Local Disk =  1TB NVMe\n",
    "    Remote NFS mounted = RAID1 4TB (on Raspberry-PI 4+ 4GB) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Byte Pair Encoding\n",
    "\n",
    "Although feasible with the proposed encoding, [BPE](https://en.wikipedia.org/wiki/Byte_pair_encoding) compression will not be dealt with in the current and is left as future work. The posibilities for BPE are:\n",
    " * Circular Convolution (in the given order) <- I would bet for this encoding type: in pytorch is with padding_type = circular\n",
    " * Additive (although this one can be a problem)\n",
    " * Other ...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Class advice impossible in Python3.  Use the @implementer class decorator instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-5e943baeb2bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtrainer_helpers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdata_loader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# from prepare_data import *\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/mix_nlp/utf8/models.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mweight_norm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# from fairseq.modules.dynamic_convolution import DynamicConv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mfairseq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightconv\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLightConvEncoderLayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_architecture\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfairseq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpositional_embedding\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPositionalEmbedding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv3/lib/python3.8/site-packages/fairseq-0.9.0-py3.8-linux-x86_64.egg/fairseq/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fairseq.progress_bar'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mfairseq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriterions\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfairseq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfairseq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv3/lib/python3.8/site-packages/fairseq-0.9.0-py3.8-linux-x86_64.egg/fairseq/criterions/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfairseq\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mregistry\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mfairseq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriterions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfairseq_criterion\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFairseqCriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLegacyFairseqCriterion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv3/lib/python3.8/site-packages/fairseq-0.9.0-py3.8-linux-x86_64.egg/fairseq/criterions/fairseq_criterion.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_Loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mfairseq\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv3/lib/python3.8/site-packages/fairseq-0.9.0-py3.8-linux-x86_64.egg/fairseq/utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfairseq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeters\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msafe_round\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mfairseq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgelu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgelu_accurate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfairseq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultihead_attention\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMultiheadAttention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv3/lib/python3.8/site-packages/fairseq-0.9.0-py3.8-linux-x86_64.egg/fairseq/modules/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mkmeans_vector_quantizer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKmeansVectorQuantizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mlayer_drop\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLayerDropModuleList\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mlayer_norm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFp32LayerNorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLayerNorm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mlearned_positional_embedding\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLearnedPositionalEmbedding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mlightweight_convolution\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLightweightConv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLightweightConv1dTBC\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv3/lib/python3.8/site-packages/fairseq-0.9.0-py3.8-linux-x86_64.egg/fairseq/modules/layer_norm.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mapex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalization\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFusedLayerNorm\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_FusedLayerNorm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mhas_fused_layernorm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv3/lib/python3.8/site-packages/apex/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m from apex.exceptions import (ApexAuthSecret,\n\u001b[1;32m     17\u001b[0m                              ApexSessionSecret)\n\u001b[0;32m---> 18\u001b[0;31m from apex.interfaces import (ApexImplementation,\n\u001b[0m\u001b[1;32m     19\u001b[0m                              IApex)\n\u001b[1;32m     20\u001b[0m from apex.lib.libapex import (groupfinder,\n",
      "\u001b[0;32m~/venv3/lib/python3.8/site-packages/apex/interfaces.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mApexImplementation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \"\"\" Class so that we can tell if Apex is installed from other \n\u001b[1;32m     12\u001b[0m     \u001b[0mapplications\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv3/lib/python3.8/site-packages/apex/interfaces.py\u001b[0m in \u001b[0;36mApexImplementation\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mapplications\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \"\"\"\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mimplements\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIApex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/venv3/lib/python3.8/site-packages/zope/interface/declarations.py\u001b[0m in \u001b[0;36mimplements\u001b[0;34m(*interfaces)\u001b[0m\n\u001b[1;32m    704\u001b[0m     \u001b[0;31m# the coverage for this block there. :(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mPYTHON3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 706\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ADVICE_ERROR\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m'implementer'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    707\u001b[0m     \u001b[0m_implements\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"implements\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterfaces\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassImplements\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Class advice impossible in Python3.  Use the @implementer class decorator instead."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from models import *\n",
    "from trainer_helpers import *\n",
    "from data_loader import *\n",
    "# from prepare_data import *\n",
    "from utils import *\n",
    "from tools import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = '/home/leo/projects/Datasets/text/selected_monofile/partitions'\n",
    "\n",
    "fpaths = get_all_files_recurse(BASE_PATH) \n",
    "\n",
    "train_files = [f for f in fpaths if 'train' in f]\n",
    "dev_files = [f for f in fpaths if 'dev' in f]\n",
    "valid_files = [f for f in fpaths if 'valid' in f]\n",
    "\n",
    "train_glue_files = [f for f in train_files if 'glue-' in f]\n",
    "dev_glue_files = [f for f in dev_files if 'glue-' in f]\n",
    "\n",
    "train_all_files = [f for f in train_files if 'all' in f]\n",
    "test_all_files = [f for f in dev_files if 'all' in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files = [ f for f in train_files if 'glue' not in f and 'all' not in f]\n",
    "test_files = [ f for f in dev_files if 'glue' not in f and 'all' not in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codebook_name = \"codes/adhoc-codebook-1871.pkl\"\n",
    "import pickle\n",
    "codebook_path = '/home/leo/projects/mix_nlp/utf8/codes/adhoc-codebook-1871.pkl'\n",
    "f = open(codebook_path, 'rb')\n",
    "codebook, char2int, int2char = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = ConvModel(codebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_parameters(model), count_trainable_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# commented to avoid accidental training while \n",
    "# %%time\n",
    "# main(model, train_files, test_files, codebook_path,\n",
    "# #      batch_size=10, \n",
    "# #      batch_size=175, # with opt_level=O1 this is the max\n",
    "#      batch_size=185, # this one works with opt_level=O2\n",
    "# #     optimizer='FusedAdam',  # Adam goes down really fast but then starts giving losses as NaN\n",
    "#      optimizer='FusedLAMB',  # Fused lamb decreases slowly but steady and goes to better loss than Adam. NaN after 21730 batches, 13h30m36s\n",
    "# #     optimizer='FusedNovoGrad', # is definetly the slowest one at the beginning, stabilizes at the worst value\n",
    "#      opt_level='O2',\n",
    "#      add_str_noise_to_input=True,\n",
    "#      test_period=-1,  # No tests, as I don't know why they are not called ... FIXME\n",
    "# #      checkpoint_period=10,\n",
    "#      checkpoint_period=200,\n",
    "#      checkpoint_path=\"/media/nfs/mix_nlp/checkpoints\"\n",
    "#     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First complete with Lang Model try (interrupted for time things)\n",
    "\n",
    "    Batch Id: 1 | Timestamp 2020-02-14T16:49:10.407032\n",
    "    TEST Batch Id: 1 | Timestamp 2020-02-14T16:50:29.512620\n",
    "    TEST Batch Id: 62 | Timestamp 2020-02-14T18:11:37.447121\n",
    "    Batch Id: 1249 | Timestamp 2020-02-14T18:12:09.529383\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint = {\n",
    "#                 'model': model.state_dict(),\n",
    "#                 'optimizer': optimizer.state_dict(),\n",
    "#                 'amp': amp.state_dict()\n",
    "#             }\n",
    "import os\n",
    "chkp_path = \"/media/nfs/mix_nlp/checkpoints\"\n",
    "# chkp = \"amp-checkpoint_opt-O2_batch-800_loss-0.006_2020-02-18T10:52:05.255814.pt\"\n",
    "# chkp = \"amp-checkpoint_opt-O2_batch-9300_loss-0.534_2020-02-19T00:11:20.645807.pt\"\n",
    "# chkp = \"amp-checkpoint_opt-O2_batch-100_loss-0.006_2020-02-19T10:18:54.487049.pt\"\n",
    "chkp = \"selected/amp-checkpoint_opt-O2_batch-11200_loss-0.544_2020-02-19T18:08:42.975215.pt\"\n",
    "chkp_fname = os.path.join(chkp_path, chkp)\n",
    "\n",
    "def load_checkpoint(clean_model, fname, optimizer=None, amp=None):\n",
    "    chkp = torch.load(fname)\n",
    "    clean_model.load_state_dict(chkp['model'])\n",
    "    if optimizer:\n",
    "        optimizer.load_state_dict(chkp['optimizer'])\n",
    "    if amp:\n",
    "        amp.load_state_dict(chkp['amp'])\n",
    "    return chkp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "load_checkpoint(model, chkp_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeds = model.embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embweights = embeds.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embweights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embweights = embweights.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embweights.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Something is WRONG during training, it is training the Embedding layer that I DONT want to touch.\n",
    "Even if the requires_grad is False\n",
    "\n",
    "There is a discussion [here](https://discuss.pytorch.org/t/why-is-it-when-i-call-require-grad-false-on-all-my-params-my-weights-in-the-network-would-still-update/22126/15) about it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeds.weight.requires_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When preloading a trained model the FusedAdam is less stable and achieves worst performance than FusedLamb.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chkp_path = \"/media/nfs/mix_nlp/checkpoints\"\n",
    "# chkp_fname = os.path.join(chkp_path, \"amp-checkpoint_opt-O2_loss-0.003_2020-02-17T13:12:18.881112.pt\")\n",
    "# chkp_fname = os.path.join(chkp_path, \"amp-checkpoint_opt-O2_loss-0.004_2020-02-17T13:39:38.887943.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chkp = load_checkpoint(model, chkp_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.embeds.weight.requires_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training results without touching the embeddings is worst than with it.... this is crap then I need to find some solution wihtout touching the embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Notes:\n",
    "\n",
    "Starting the training with FusedAdam until it fails (NaN) accelerates training a lot.\n",
    "After I reloaded these weights and used FusedLamb and it starts better getting to better loss faster.\n",
    "\n",
    "Nevertheless, adding the Language Modeling tasks duplicates training data volume (data augmentation), hence the training time duplicates too.\n",
    "\n",
    "The learning curves advance better for language determination, concerning the language model training, it seems to reach astable level after about 1K batches, though the language determination of LM tasks keeps improving slowly. \n",
    "\n",
    "The general loss (Task + lang determination and NO Language Model) draws a 90degree S, first going doing very fast (after adam warmup) then going to horizontal and then back again parallel to the original FusedLamb training (the original one was WITHOUT language model task).\n",
    "\n",
    "I'll do this training, then I'll do a Dynamic Convolution column trianing with the same kind of output as the ConvModel (that contains also one transformer layer) and\n",
    "\n",
    "After that I'll do an encoder-decoder architecture fusing both pre-trained models and adding a few memory layers on top (one or two memory encoder layers and maybe 3-5 memory decoding layers) .... I still have to unerstand correctly where this is going and how to make it happen .... \n",
    "\n",
    "It must also be noted that as the training set is gigantonormous (for the current setup and network) the train datapoints are never repeated so basically the loss of the train evaluation would be equivalent to the dev evaluation.\n",
    "\n",
    "\n",
    "Training with Language Model as well as with tasks seems to give worst loss than training without it before getting to a NaN , nevertheless, after this pretraining and restarting the task training without the  Language Model alterations seems to drastically improve the loss results. Although later during training it again breaks jumping to high loss and having NaNs again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=10\n",
    "num_workers=6\n",
    "max_seq_len=512\n",
    "add_noise_to_task=True\n",
    "add_str_noise_to_input=True\n",
    "\n",
    "test_dataset = Txt2TxtDataset(test_files, char2int, max_len=max_seq_len, add_noise_to_task=add_noise_to_task,\n",
    "                              add_str_noise_to_input=add_str_noise_to_input)\n",
    "test_data_loader = DataLoader(test_dataset, batch_size=batch_size,\n",
    "                              pin_memory=True,\n",
    "                              num_workers=num_workers, worker_init_fn=Txt2TxtDataset.worker_init_fn)\n",
    "\n",
    "# chkp = load_checkpoint(model, chkp_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datas = []\n",
    "data_count = 0\n",
    "\n",
    "for d in test_dataset:\n",
    "    datas.append(d)\n",
    "    data_count+=1\n",
    "    if data_count > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "batches = []\n",
    "for l in test_data_loader:\n",
    "    batches.append(l)\n",
    "    if len(batches) > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b0 = batches[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(b0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "results = []\n",
    "for batch_data in batches:\n",
    "    batch = []\n",
    "    for d in batch_data:\n",
    "        batch.append(d.to(device))\n",
    "    batch_data = batch\n",
    "    noise_masked, noise_target, source, target, target_lang = batch_data\n",
    "    msk_res, msk_lang_res = model(noise_masked)\n",
    "    tsk_res, tsk_lang_res = model(source)\n",
    "    \n",
    "    msk_res = msk_res.cpu().detach().numpy()\n",
    "    msk_lang_res = msk_lang_res.cpu().detach().numpy()\n",
    "    tsk_res = tsk_res.cpu().detach().numpy()\n",
    "    tsk_lang_res = tsk_lang_res.cpu().detach().numpy()\n",
    "    \n",
    "    del(noise_masked)\n",
    "    del(noise_target)\n",
    "    del(source)\n",
    "    del(target)\n",
    "    del(target_lang)\n",
    "        \n",
    "    res = (msk_res, msk_lang_res, tsk_res, tsk_lang_res)\n",
    "    results.append(res)\n",
    "    torch.cuda.empty_cache()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# r0 = results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r0[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lmlangr0 = r0[1][0,:,:].reshape(60,1871)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# amax = np.argmax(lmlangr0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch2txt(batch):\n",
    "    all_txt = []\n",
    "    for i in range(batch.shape[0]):\n",
    "        txt = code2str(batch[i,:].reshape(-1), int2char)\n",
    "        all_txt.append(txt)\n",
    "    return all_txt\n",
    "\n",
    "def result_batch2txt(batch):\n",
    "    all_txt = []\n",
    "#     print(batch.shape)\n",
    "    idxs = np.argmax(batch, axis=-1)\n",
    "    for i in range(idxs.shape[0]):\n",
    "        idx = idxs[i,:]\n",
    "#         print(idx.shape)\n",
    "        txt = code2str(idx, int2char)\n",
    "        all_txt.append(txt)\n",
    "    return all_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b00 = batches[0][0][0,:].reshape(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code2str(b00.cpu().detach().numpy(), int2char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_compare = []\n",
    "\n",
    "for batch_data, batch_results in zip(batches, results):\n",
    "    txt = []\n",
    "    for d in batch_data:\n",
    "        txt.append(batch2txt(d.cpu().detach().numpy()))\n",
    "    for d in batch_results:\n",
    "        txt.append(result_batch2txt(d))\n",
    "    res = zip(*txt)\n",
    "    txt_compare = res\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig = []\n",
    "for batch_data in batches:\n",
    "    txt = []\n",
    "    for d in batch_data:\n",
    "        d = d.cpu().detach().numpy()\n",
    "        txt.append(batch2txt(d))\n",
    "    orig = zip(*txt)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_compare = list(txt_compare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean null characters\n",
    "txt_nonull = [t.replace(\"â—Œ\",\"\") for b in txt_compare for t in b]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_nonull[0:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# txt_nonull[18]\n",
    "txt_nonull[9:38]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code2str(lmlang, int2char)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Made a mistake on the data training generation ... already fixed, now it should do better during inference (after the new training ... of an entire day)\n",
    "\n",
    "First results on training with LM  + Tasks on the ConvModel, it does NOT work well, language detection is good, but the tasks are not well answered, the network is like trying to do text cleanup instead of doing the task correctly. Now I'm training a new "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.argmax?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training with mixed precision always falls later in NaN, while training with float32 needs more memory (and time) and thus smaller batches leading to oscilation without really learning anything new besides the things that were pre-trained before.....\n",
    "\n",
    "Need to do gradient accumulation or loss accumulation for many mini-batches to create a virtual big batch and see if that makes the problem go away.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
